{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b61d9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #for no tensorflow warnings\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692027b",
   "metadata": {},
   "source": [
    "# Try Clustering Neurons with similar Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4709395",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f378592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 28, 28).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96dac5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate jacobian -- single input \n",
    "def get_jacobian(inp):\n",
    "    outputs = []\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(inp)\n",
    "        outputs.append(inp)\n",
    "        out = inp\n",
    "        for layer in model.layers:\n",
    "            out = layer(out)\n",
    "            tape.watch(out)\n",
    "            outputs.append(out)\n",
    "        ret = out\n",
    "        print([var.name for var in tape.watched_variables()])\n",
    "\n",
    "    jacobian_list = []\n",
    "    for o in outputs:\n",
    "        grad = tape.jacobian(ret, o)# works dret/do\n",
    "        assert grad.shape[0] == 1\n",
    "        if grad.shape[3] == 28:#TODO: hard-coded -- find way to only squeeze dim with shape=1\n",
    "            grad = tf.reshape(grad, shape=(grad.shape[1], grad.shape[3], grad.shape[4]))\n",
    "        else:\n",
    "            grad = tf.reshape(grad, shape=(grad.shape[1], grad.shape[3]))        \n",
    "        jacobian_list.append(tf.transpose(grad)) # i-th row corresponds to da_i/dy for activation neuron a_i\n",
    "        #jacobian_list.append(grad)\n",
    "    return jacobian_list\n",
    "\n",
    "# calculate jacobian -- multiple inputs\n",
    "def calc_avg_jacobian(inputs):\n",
    "    jac_total = None\n",
    "    for i in range(inputs.shape[0]):\n",
    "        inp_test = inputs[i]\n",
    "        inp_test = tf.expand_dims(inp_test, axis=0)\n",
    "        jac_list = get_jacobian(inp_test)\n",
    "        if not jac_total:\n",
    "            jac_total = jac_list\n",
    "        else:\n",
    "            for i in range(len(jac_total)):\n",
    "                jac_total[i] += jac_list[i]\n",
    "    return jac_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "909d675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:22<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "num_samples=30\n",
    "x_test_labeli = tf.squeeze(x_test[tf.where(y_test == float(0))])\n",
    "inpt = x_test_labeli[0:num_samples]\n",
    "jac_dict = calc_avg_jacobian(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5880d860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 119,910\n",
      "Trainable params: 119,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dbf59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss():        \n",
    "    def loss(y_true, y_pred):\n",
    "        y_soft = tf.keras.activations.softmax(y_pred, axis=1)\n",
    "        loss_soft=keras.losses.SparseCategoricalCrossentropy()(y_true, y_soft)\n",
    "        return loss_soft\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b143ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=softmax_loss(), \n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04769bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=2,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ada8f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c55257",
   "metadata": {},
   "source": [
    "### calculate Jacobian for same-class inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e3d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2366/2316614083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_test_labeli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_labeli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mjac_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_avg_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradients_class_{0}.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2366/184299090.py\u001b[0m in \u001b[0;36mcalc_avg_jacobian\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0minp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0minp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mjac_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjac_total\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mjac_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2366/184299090.py\u001b[0m in \u001b[0;36mget_jacobian\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#TODO: hard-coded -- find way to only squeeze dim with shape=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "num_samples = 50\n",
    "for i in range(0, 10):    \n",
    "    x_test_labeli = tf.squeeze(x_test[tf.where(y_test == float(i))])\n",
    "    inpt = x_test_labeli[0:num_samples]\n",
    "    jac_total = calc_avg_jacobian(inpt)\n",
    "    np.save(\"gradients_class_{0}.npy\".format(i), jac_total[2:-1], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714232d",
   "metadata": {},
   "source": [
    "## save and load Jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6572969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"gradients_class_{0}.npy\".format(i), jac_total[2:-1], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e6aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_per_class = {}\n",
    "for i in range(0, 10):\n",
    "    jac_per_class[i] = np.load(\"gradients_class_{0}.npy\".format(i), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61f57d",
   "metadata": {},
   "source": [
    "## normalize Jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe82e064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ba5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_euclidean_dist(A):\n",
    "    r = tf.reduce_sum(A*A, 1)\n",
    "    r = tf.reshape(r, [-1, 1])    # turn r into column vector\n",
    "    D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
    "    return tf.math.abs(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "27c9c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def pairwise_cosine_dist(A):\n",
    "    D = sklearn.metrics.pairwise.cosine_distances(A)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589c2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_l2normalized(jac_total):\n",
    "    # every row-vector (here: da_i/dy for one a_i-neuron) has length 1\n",
    "    jac_total_l2normalized = []\n",
    "    jac_l2norm_dists = []\n",
    "    for i in range(len(jac_total)):\n",
    "        j = jac_total[i]\n",
    "        a = tf.math.l2_normalize(j, axis=1)\n",
    "        jac_total_l2normalized.append(a)\n",
    "        d = pairwise_euclidean_dist(a)\n",
    "        jac_l2norm_dists.append(d)\n",
    "    return jac_l2norm_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "209f8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_unnormalized(jac_total):\n",
    "    jac_l2norm_dists = []\n",
    "    for i in range(len(jac_total)):\n",
    "        j = jac_total[i]\n",
    "        #d = pairwise_euclidean_dist(j)\n",
    "        d = pairwise_cosine_dist(j)\n",
    "        jac_l2norm_dists.append(d)\n",
    "    return jac_l2norm_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1200bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_normalized(jac_total):\n",
    "    # all elements lie between 0 and 1\n",
    "    jac_total_normalized = []\n",
    "    jac_norm_dists = []\n",
    "    for i in range(len(jac_total)):\n",
    "        j = jac_total[i]\n",
    "        mean = tf.expand_dims(tf.math.reduce_mean(j, axis=1),axis=1)\n",
    "        stdv =  tf.expand_dims(tf.math.reduce_std(j, axis=1),axis=1)\n",
    "        a = (j - mean)/stdv\n",
    "        jac_total_normalized.append(a)\n",
    "        d = pairwise_euclidean_dist(a)\n",
    "        jac_norm_dists.append(d)\n",
    "    return jac_norm_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "569c1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(5, 10, 100, 100)\n",
      "tf.Tensor([0.9130637 0.9090496 0.9069576 0.7158661 0.5781299], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# compute da_i/dy da_j/dy distances for each label-class, then average over distances\n",
    "#dists = jac_l2normalized(jac_per_class[0])\n",
    "dist_fn = jac_unnormalized\n",
    "dists = dist_fn(jac_per_class[0])\n",
    "\n",
    "dists_tensor = tf.expand_dims(tf.convert_to_tensor(jac_l2normalized(jac_per_class[0])), axis=1)\n",
    "for class_ in range(1, 10):\n",
    "    dists2 = dist_fn(jac_per_class[class_])\n",
    "    dists2_tensor = tf.expand_dims(tf.convert_to_tensor(dists2), axis=1)\n",
    "    dists_tensor = tf.concat([dists_tensor, dists2_tensor], axis=1)\n",
    "    for j in range(len(dists2)):\n",
    "        dists[j] += dists2[j]\n",
    "for j in range(len(dists)):\n",
    "    dists[j] = dists[j]/10\n",
    "    \n",
    "print(dists_tensor.shape)\n",
    "stdvs = tf.math.reduce_std(dists_tensor, axis=1)\n",
    "print(tf.math.reduce_max(stdvs, axis=(1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3bd8a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use distances over _one_ class\n",
    "class_idx = 1\n",
    "dists = jac_unnormalized(jac_per_class[class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "441fc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only da_i/dy_k of input-class k --> build \"jacobian\" with less noise\n",
    "# init new jacs\n",
    "num_classes = 10\n",
    "denoised_jacobian = np.zeros((5, 100, num_classes)) # shape = (#layers, #neurons_p_layer, #out_neurons)\n",
    "for idx in jac_per_class:\n",
    "    denoised_jacobian[:, :, idx] = jac_per_class[idx][:,:,idx]\n",
    "\n",
    "dists = jac_normalized(denoised_jacobian) # list of layer-1 dists in idx 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293f7a9",
   "metadata": {},
   "source": [
    "## save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318ceaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #for no tensorflow warnings\"\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7900cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No config for GTSRB data provided\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "from models import *\n",
    "from src.main import Cluster_Class, set_file_model, set_keras_model\n",
    "from src.models import Keras_Model\n",
    "from src.cluster_methods import SensitivityAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e7fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('MNIST_5x100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "74e975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss():        \n",
    "    def loss(y_true, y_pred):\n",
    "        y_soft = tf.keras.activations.softmax(y_pred, axis=1)\n",
    "        loss_soft=keras.losses.SparseCategoricalCrossentropy()(y_true, y_soft)\n",
    "        return loss_soft\n",
    "    return loss\n",
    "new_model = tf.keras.models.load_model('MNIST_5x100.h5', custom_objects={'loss': softmax_loss()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5d11c",
   "metadata": {},
   "source": [
    "## cluster similar neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "47e162b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = set_keras_model(new_model) # layer printed last does not get clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "78256001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9746000170707703\n",
      "0 0.9867346882820129\n",
      "1 0.9885462522506714\n",
      "2 0.9593023061752319\n",
      "3 0.9613861441612244\n",
      "4 0.9867616891860962\n",
      "5 0.9652466177940369\n",
      "6 0.9780793190002441\n",
      "7 0.9747081995010376\n",
      "8 0.9691991806030273\n",
      "9 0.9742318987846375\n"
     ]
    }
   ],
   "source": [
    "# only use distances over _one_ class\n",
    "m.update_keras()\n",
    "m.test_accuracy()\n",
    "for idx in range(10):\n",
    "    print(idx, m.test_MNIST_labelacc(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fa275ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = SensitivityAnalysis(dists_l1=dists[0],dists_l2=dists[1], dists_l3=dists[2], \n",
    "                         dists_l4=dists[3],dists_l5=dists[4], eps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "adbe5e3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9746000170707703\n",
      "----- [Get Activations] -----\n",
      "----- [Start Clustering] -----\n",
      "   - Layer 1\n",
      "----- [Get Clusters] -----\n",
      "K= 99\n",
      "DO NOTHING\n",
      "[]\n",
      "   - Layer 2\n",
      "----- [Get Clusters] -----\n",
      "K= 99\n",
      "DO NOTHING\n",
      "[]\n",
      "   - Layer 3\n",
      "----- [Get Clusters] -----\n",
      "K= 3\n",
      "12  different clusters found \n",
      "num clustered neurons= 57\n",
      "[(0, array([ 2, 12, 24, 25, 29, 30, 38, 46, 59, 61, 68, 69, 72, 80, 90, 98]), 25, 0, 55.223244), (1, array([ 4, 21, 50]), 21, 0, 23.908281), (2, array([ 5, 43]), 5, 0, 35.683643), (3, array([ 7, 28, 79]), 79, 0, 44.760746), (4, array([10, 15, 16, 17, 32, 41, 44, 74, 78, 85, 97, 99]), 41, 0, 70.96557), (5, array([26, 34, 62, 66, 71, 81]), 62, 0, 55.346405), (6, array([31, 92]), 31, 0, 36.940388), (7, array([36, 37, 95]), 95, 0, 23.067339), (8, array([42, 60, 64, 89]), 64, 0, 28.166096), (9, array([45, 55]), 45, 0, 33.21388), (10, array([48, 52]), 48, 0, 37.31882), (11, array([91, 93]), 91, 0, 27.665648)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 4\n",
      "----- [Get Clusters] -----\n",
      "K= 4\n",
      "11  different clusters found \n",
      "num clustered neurons= 27\n",
      "[(0, array([ 1, 10, 25, 86]), 25, 0, 55.226192), (1, array([3, 8]), 3, 0, 36.01825), (2, array([18, 77]), 18, 0, 20.69248), (3, array([19, 69]), 19, 0, 39.391457), (4, array([20, 32, 73]), 73, 0, 29.698513), (5, array([28, 59, 62, 99]), 28, 0, 62.446682), (6, array([30, 87]), 30, 0, 71.04688), (7, array([49, 72]), 49, 0, 40.203285), (8, array([53, 83]), 53, 0, 25.698019), (9, array([68, 84]), 68, 0, 26.373697), (10, array([91, 96]), 91, 0, 73.355225)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 5\n",
      "----- [Get Clusters] -----\n",
      "K= 5\n",
      "10  different clusters found \n",
      "num clustered neurons= 20\n",
      "[(0, array([12, 42]), 12, 0, 42.15148), (1, array([15, 75]), 15, 0, 48.43294), (2, array([19, 76]), 19, 0, 0.0), (3, array([21, 31]), 21, 0, 22.102247), (4, array([27, 52]), 27, 0, 60.313774), (5, array([30, 39]), 30, 0, 74.58105), (6, array([44, 71]), 44, 0, 72.10716), (7, array([51, 78]), 51, 0, 96.24961), (8, array([53, 57]), 53, 0, 9.851127), (9, array([54, 99]), 54, 0, 86.51124)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "Overall Time:  3.015502452850342\n",
      "Test set accuracy:  0.8598999977111816\n",
      "----- [End Clustering] -----\n",
      "0.8598999977111816 {'rr': 0.14200000000000002, 'time': 5.453428745269775, 'rr_rel': 0.142}\n"
     ]
    }
   ],
   "source": [
    "# 50-3 tries clustering the third layer, 50-2 tries the second, 50-1 the first\n",
    "cc = Cluster_Class(m, [1,1,100-3,100-4,100-5], cl_method=\"gradients\", SA=SA)\n",
    "acc, dic = cc.perform_clustering(verbose=True)\n",
    "print(acc, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9b5070a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr dist-dependency on label # 1\n",
      "0 0.6510204076766968\n",
      "1 0.8757709264755249\n",
      "2 0.7306201457977295\n",
      "3 0.9683168530464172\n",
      "4 0.709775984287262\n",
      "5 0.8206278085708618\n",
      "6 0.9874739050865173\n",
      "7 0.9834630489349365\n",
      "8 0.9476386308670044\n",
      "9 0.9167492389678955\n"
     ]
    }
   ],
   "source": [
    "print(\"curr dist-dependency on label #\", class_idx)\n",
    "for idx in range(10):\n",
    "    print(idx, m.test_MNIST_labelacc(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "eaf6d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9746000170707703\n",
      "----- [Get Activations] -----\n",
      "----- [Start Clustering] -----\n",
      "   - Layer 1\n",
      "----- [Get Clusters] -----\n",
      "K= 99\n",
      "[]\n",
      "   - Layer 2\n",
      "----- [Get Clusters] -----\n",
      "K= 99\n",
      "[]\n",
      "   - Layer 3\n",
      "----- [Get Clusters] -----\n",
      "K= 46\n",
      "sample  100 46\n",
      "[(0, array([ 2,  8, 18, 20, 30, 62, 68, 80, 82, 94, 96]), 94, 0, 54.99963), (1, array([ 1,  9, 19, 27, 28, 29, 32, 33, 36, 44, 49, 51, 57, 71, 79, 84, 90,\n",
      "       93]), 90, 0, 67.02696), (2, array([ 7, 11, 22, 35, 42, 47, 59, 63, 65, 67, 69, 70, 73, 77, 95, 98, 99]), 7, 0, 53.4461)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 4\n",
      "----- [Get Clusters] -----\n",
      "K= 34\n",
      "sample  100 34\n",
      "[(0, array([ 6, 41, 55, 56, 62, 65, 75, 79, 94]), 6, 0, 77.30345), (1, array([ 0,  1,  5,  7, 45, 51, 53, 54, 73, 74, 77, 93, 95, 96]), 73, 0, 77.68521), (2, array([ 2, 10, 11, 21, 31, 33, 34, 49, 58, 71, 99]), 11, 0, 69.685455)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 5\n",
      "----- [Get Clusters] -----\n",
      "K= 51\n",
      "sample  100 51\n",
      "[(0, array([16, 17, 20, 25, 26, 29, 37, 42, 49, 57, 68, 72, 90, 91, 95]), 20, 0, 89.31959), (1, array([ 1,  5,  8, 18, 21, 22, 23, 27, 32, 34, 36, 38, 40, 54, 56, 67, 70,\n",
      "       73, 76, 80, 81, 86, 89]), 36, 0, 92.58626), (2, array([ 6, 10, 11, 12, 28, 33, 39, 43, 51, 52, 53, 78, 99]), 10, 0, 115.272064)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "Overall Time:  3.076920747756958\n",
      "Test set accuracy:  0.6304000020027161\n",
      "----- [End Clustering] -----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6304000020027161, {'rr': 0.244, 'time': 5.310251951217651, 'rr_rel': 0.244})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50-3 tries clustering the third layer, 50-2 tries the second, 50-1 the first\n",
    "cc = Cluster_Class(m, [1,1,100-46,100-34,100-51], cl_method=\"random\")\n",
    "cc.perform_clustering(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3871a32",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917d0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9760000109672546\n",
      "----- [Get Activations] -----\n",
      "----- [Start Clustering] -----\n",
      "   - Layer 1\n",
      "----- [Get Clusters] -----\n",
      "[(0, array([30, 75, 76]), 30, 0, 11.99565)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 2\n",
      "----- [Get Clusters] -----\n",
      "[(0, array([ 4,  7, 14, 15, 26, 45, 72, 97]), 7, 0, 12.251186)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 3\n",
      "----- [Get Clusters] -----\n",
      "[(0, array([ 5, 22, 39, 57, 84, 88, 89, 95, 98]), 5, 0, 10.84604)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 4\n",
      "----- [Get Clusters] -----\n",
      "[(0, array([12, 15, 18, 54, 65, 87]), 12, 0, 7.6198654)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "   - Layer 5\n",
      "----- [Get Clusters] -----\n",
      "[(0, array([ 4,  5,  7,  8, 16, 28, 30, 43, 83, 86, 88, 90, 91, 94, 97]), 4, 0, 11.6834)]\n",
      "----- [Apply the Clustering to the Network] -----\n",
      "Overall Time:  3.1475541591644287\n",
      "Test set accuracy:  0.972100019454956\n",
      "----- [End Clustering] -----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.972100019454956,\n",
       " {'rr': 0.07199999999999995, 'time': 5.223412036895752, 'rr_rel': 0.072})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if not clustering changes network\n",
    "cc = Cluster_Class(m, [10], cl_method=\"dbscan\")\n",
    "cc.perform_clustering(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa3ba68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f7c02232c40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.update_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc4585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 23:12:24.210482: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-09 23:12:24.225949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2700905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9232000112533569\n",
      "dict_keys(['W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4'])\n"
     ]
    }
   ],
   "source": [
    "km = set_keras_model(new_model)\n",
    "km.test_accuracy()\n",
    "print(km.params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d37c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
